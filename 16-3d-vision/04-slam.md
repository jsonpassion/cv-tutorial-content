# SLAM ê¸°ì´ˆ

> ë™ì‹œì  ìœ„ì¹˜ì¶”ì • ë° ì§€ë„ì‘ì„±

## ê°œìš”

[ì¹´ë©”ë¼ ê¸°í•˜í•™](./03-camera-geometry.md)ì—ì„œ ë‘ ì´ë¯¸ì§€ ì‚¬ì´ì˜ ê¸°í•˜í•™ì  ê´€ê³„ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤. ì´ì œ ì¹´ë©”ë¼ê°€ **ì›€ì§ì´ë©´ì„œ ì—°ì†ìœ¼ë¡œ ì´¬ì˜**í•œë‹¤ë©´ ì–´ë–¨ê¹Œìš”? **SLAM(Simultaneous Localization and Mapping)**ì€ ë¡œë´‡ì´ë‚˜ ì¹´ë©”ë¼ê°€ **ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ë©´ì„œ ë™ì‹œì— í™˜ê²½ ì§€ë„ë¥¼ ìƒì„±**í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ììœ¨ì£¼í–‰, AR/VR, ë“œë¡  ë„¤ë¹„ê²Œì´ì…˜ì˜ í•µì‹¬ ê¸°ìˆ ì´ì£ .

**ì„ ìˆ˜ ì§€ì‹**: [ì¹´ë©”ë¼ ê¸°í•˜í•™](./03-camera-geometry.md), [íŠ¹ì§•ì  ê²€ì¶œ](../02-classical-cv/04-feature-detection.md)
**í•™ìŠµ ëª©í‘œ**:
- SLAMì˜ ê¸°ë³¸ ê°œë…ê³¼ "ë‹­ê³¼ ë‹¬ê±€" ë¬¸ì œë¥¼ ì´í•´í•œë‹¤
- Visual SLAMì˜ í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ êµ¬ì¡°ë¥¼ íŒŒì•…í•œë‹¤
- ORB-SLAM3ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•œë‹¤
- ë£¨í”„ í´ë¡œì§•ê³¼ ë²ˆë“¤ ì¡°ì •ì˜ ì—­í• ì„ ì•ˆë‹¤

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

ìŠ¤ë§ˆíŠ¸í°ìœ¼ë¡œ ì‹¤ë‚´ë¥¼ ìŠ¤ìº”í•´ì„œ 3D ëª¨ë¸ì„ ë§Œë“œëŠ” ì•±, AR ê¸€ë¼ìŠ¤ê°€ í˜„ì‹¤ ê³µê°„ì— ê°€ìƒ ê°ì²´ë¥¼ ê³ ì •í•˜ëŠ” ê¸°ëŠ¥, ë¡œë´‡ ì²­ì†Œê¸°ê°€ ì§‘ ì•ˆì„ ëŒì•„ë‹¤ë‹ˆë©° ì§€ë„ë¥¼ ë§Œë“œëŠ” ê²ƒ â€” ëª¨ë‘ **SLAM**ì— ê¸°ë°˜í•©ë‹ˆë‹¤. íŠ¹íˆ GPSê°€ ì•ˆ ë˜ëŠ” ì‹¤ë‚´ í™˜ê²½ì—ì„œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ëŠ” ê±°ì˜ ìœ ì¼í•œ ë°©ë²•ì´ì£ . ììœ¨ì£¼í–‰ ë¡œë´‡, AR ê¸°ê¸°, ë“œë¡  ë“± **ì›€ì§ì´ëŠ” ëª¨ë“  ìŠ¤ë§ˆíŠ¸ ê¸°ê¸°**ì— í•„ìˆ˜ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: SLAMì´ë€?

> ğŸ’¡ **ë¹„ìœ **: ëˆˆì„ ê°€ë¦¬ê³  ì²˜ìŒ ê°€ë³´ëŠ” ê±´ë¬¼ì— ë“¤ì–´ê°”ë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”. ì†ìœ¼ë¡œ ë”ë“¬ìœ¼ë©° **"ë‚´ê°€ ì–´ë””ì— ìˆì§€?"**ì™€ **"ì´ ê±´ë¬¼ì€ ì–´ë–¤ êµ¬ì¡°ì§€?"**ë¥¼ ë™ì‹œì— ì•Œì•„ë‚´ì•¼ í•©ë‹ˆë‹¤. ì§€ë„ê°€ ìˆìœ¼ë©´ ìœ„ì¹˜ë¥¼ ì•Œ ìˆ˜ ìˆê³ , ìœ„ì¹˜ë¥¼ ì•Œë©´ ì§€ë„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ”ë° â€” ë‘˜ ë‹¤ ì—†ëŠ” ìƒí™©ì—ì„œ ì‹œì‘í•´ì•¼ í•˜ì£ .

**SLAMì˜ í•µì‹¬ ë¬¸ì œ: ë‹­ê³¼ ë‹¬ê±€**

| í•„ìš”í•œ ê²ƒ | ì•Œë ¤ë©´ í•„ìš”í•œ ê²ƒ |
|-----------|------------------|
| ìœ„ì¹˜ ì¶”ì • | ì§€ë„ê°€ í•„ìš” |
| ì§€ë„ ìƒì„± | ìœ„ì¹˜ê°€ í•„ìš” |

SLAMì€ ì´ **ìˆœí™˜ ì˜ì¡´ì„±**ì„ ì ì§„ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ë¶ˆí™•ì‹¤í•˜ì§€ë§Œ, ê´€ì¸¡ì´ ìŒ“ì´ë©´ì„œ ì ì  ì •í™•í•´ì§€ì£ .

**SLAMì˜ ì¢…ë¥˜:**

| ì¢…ë¥˜ | ì„¼ì„œ | íŠ¹ì§• |
|------|------|------|
| **Visual SLAM** | ì¹´ë©”ë¼ (ë‹¨ì•ˆ/ìŠ¤í…Œë ˆì˜¤) | ì €ë ´, í’ë¶€í•œ ì •ë³´ |
| **LiDAR SLAM** | LiDAR | ì •í™•í•œ ê¹Šì´, ë¹„ìŒˆ |
| **Visual-Inertial** | ì¹´ë©”ë¼ + IMU | ë¹ ë¥¸ ì›€ì§ì„ì— ê°•ê±´ |
| **RGB-D SLAM** | RGB-D ì¹´ë©”ë¼ | ì§ì ‘ì  ê¹Šì´, ì‹¤ë‚´ ì „ìš© |

ì´ ì„¹ì…˜ì—ì„œëŠ” **Visual SLAM**ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

### ê°œë… 2: Visual SLAMì˜ êµ¬ì¡°

Visual SLAMì€ í¬ê²Œ **í”„ë¡ íŠ¸ì—”ë“œ**ì™€ **ë°±ì—”ë“œ**ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:

**í”„ë¡ íŠ¸ì—”ë“œ (Visual Odometry):**

> ğŸ’¡ **ë¹„ìœ **: ìš´ì „í•  ë•Œ ì•ì„ ë³´ê³  **"ë°©ê¸ˆ 10m ì§ì§„í•˜ê³  ì˜¤ë¥¸ìª½ìœ¼ë¡œ 15ë„ ëŒì•˜ë‹¤"**ë¥¼ íŒë‹¨í•˜ëŠ” ê²ƒ. ì—°ì†ëœ í”„ë ˆì„ ì‚¬ì´ì˜ ìƒëŒ€ì  ì›€ì§ì„ì„ ì¶”ì •í•©ë‹ˆë‹¤.

| ë‹¨ê³„ | ì—­í•  |
|------|------|
| **íŠ¹ì§• ì¶”ì¶œ** | ORB, SIFT ë“±ìœ¼ë¡œ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ |
| **íŠ¹ì§• ë§¤ì¹­** | ì—°ì† í”„ë ˆì„ ê°„ ëŒ€ì‘ì  ì°¾ê¸° |
| **ëª¨ì…˜ ì¶”ì •** | ì—í”¼í´ë¼ ê¸°í•˜í•™ìœ¼ë¡œ R, t ê³„ì‚° |
| **ì‚¼ê°í™”** | 3D ë§µí¬ì¸íŠ¸ ìƒì„± |

**ë°±ì—”ë“œ (Optimization):**

> ğŸ’¡ **ë¹„ìœ **: ì—¬í–‰ í›„ **"ë‚´ê°€ ê·¸ë¦° ì•½ë„ê°€ ë§ë‚˜?"** ê²€í† í•˜ê³  ìˆ˜ì •í•˜ëŠ” ê²ƒ. ëˆ„ì ëœ ì˜¤ì°¨ë¥¼ ì¤„ì´ê³  ì „ì²´ ê¶¤ì ê³¼ ì§€ë„ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.

| ê¸°ë²• | ì„¤ëª… |
|------|------|
| **ë²ˆë“¤ ì¡°ì • (Bundle Adjustment)** | ì¹´ë©”ë¼ í¬ì¦ˆì™€ 3D ì ì„ ë™ì‹œ ìµœì í™” |
| **í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”** | ì¹´ë©”ë¼ í¬ì¦ˆë“¤ ê°„ì˜ ê´€ê³„ ìµœì í™” |
| **ë£¨í”„ í´ë¡œì§•** | ì´ì „ì— ë°©ë¬¸í•œ ê³³ ì¸ì‹ â†’ ë“œë¦¬í”„íŠ¸ ìˆ˜ì • |

### ê°œë… 3: Visual Odometry â€” í”„ë ˆì„ ê°„ ì›€ì§ì„ ì¶”ì •

**Direct Method vs Feature-based Method:**

| ë°©ì‹ | ì›ë¦¬ | ì¥ë‹¨ì  |
|------|------|--------|
| **íŠ¹ì§• ê¸°ë°˜** | í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ â†’ ê¸°í•˜í•™ì  ê³„ì‚° | ê°•ê±´, ê³„ì‚° íš¨ìœ¨ì  |
| **ì§ì ‘ë²•** | í”½ì…€ ë°ê¸° ë³€í™” ìµœì†Œí™” | ëª¨ë“  í”½ì…€ í™œìš©, ì¡°ëª…ì— ë¯¼ê° |
| **í•˜ì´ë¸Œë¦¬ë“œ** | ë‘˜ì˜ ì¥ì  ê²°í•© | ìµœì‹  íŠ¸ë Œë“œ |

**íŠ¹ì§• ê¸°ë°˜ VO íŒŒì´í”„ë¼ì¸:**

> 1. í”„ë ˆì„ Nì—ì„œ íŠ¹ì§•ì  ì¶”ì¶œ (ORB)
> 2. í”„ë ˆì„ Nê³¼ N+1 ì‚¬ì´ íŠ¹ì§• ë§¤ì¹­
> 3. ê¸°ë³¸ í–‰ë ¬/ë³¸ì§ˆ í–‰ë ¬ ê³„ì‚°
> 4. R, t ë¶„í•´ (ìƒëŒ€ì  í¬ì¦ˆ)
> 5. ìƒˆ 3D ì  ì‚¼ê°í™”
> 6. ë§µì— ì¶”ê°€

**í‚¤í”„ë ˆì„ (Keyframe):**

ëª¨ë“  í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ë©´ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. **í‚¤í”„ë ˆì„**ë§Œ ì„ íƒí•´ì„œ ì§€ë„ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤:

- ì¶©ë¶„íˆ ì›€ì§ì˜€ì„ ë•Œ
- ìƒˆë¡œìš´ ì˜ì—­ì´ ë³´ì¼ ë•Œ
- ì¼ì • ì‹œê°„ì´ ì§€ë‚¬ì„ ë•Œ

### ê°œë… 4: ë£¨í”„ í´ë¡œì§• â€” ë“œë¦¬í”„íŠ¸ ìˆ˜ì •

> ğŸ’¡ **ë¹„ìœ **: ë™ë„¤ë¥¼ í•œ ë°”í€´ ëŒì•˜ëŠ”ë°, ì¶œë°œì ìœ¼ë¡œ ëŒì•„ì™”ì„ ë•Œ **"ì–´? ì—¬ê¸° ì•„ê¹Œ ì¶œë°œí•œ ê³³ì´ì–ì•„!"**ë¼ê³  ì¸ì‹í•˜ëŠ” ê²ƒ. ê·¸ëŸ¼ ì§€ê¸ˆê¹Œì§€ ìŒ“ì¸ ì˜¤ì°¨ë¥¼ í•œêº¼ë²ˆì— ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ë“œë¦¬í”„íŠ¸ ë¬¸ì œ:**

Visual OdometryëŠ” í”„ë ˆì„ë§ˆë‹¤ ì‘ì€ ì˜¤ì°¨ê°€ ìƒê¸°ê³ , ì´ê²Œ **ëˆ„ì **ë©ë‹ˆë‹¤. ê¸´ ê±°ë¦¬ë¥¼ ì´ë™í•˜ë©´ ì‹¤ì œ ìœ„ì¹˜ì™€ ì¶”ì • ìœ„ì¹˜ê°€ í¬ê²Œ ì–´ê¸‹ë‚˜ì£ .

**ë£¨í”„ í´ë¡œì§• ê³¼ì •:**

1. **ë£¨í”„ íƒì§€**: í˜„ì¬ ì´ë¯¸ì§€ì™€ ê³¼ê±° í‚¤í”„ë ˆì„ ë¹„êµ (Bag of Words ë“±)
2. **ê²€ì¦**: ê¸°í•˜í•™ì  ì¼ê´€ì„± í™•ì¸ (RANSAC)
3. **í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”**: ë£¨í”„ ì œì•½ ì¶”ê°€ â†’ ì „ì²´ ê¶¤ì  ìˆ˜ì •

**Bag of Words (BoW):**

ì´ë¯¸ì§€ë¥¼ **ì‹œê° ë‹¨ì–´ë“¤ì˜ ì§‘í•©**ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ê°™ì€ ì¥ì†ŒëŠ” ë¹„ìŠ·í•œ ì‹œê° ë‹¨ì–´ë¥¼ ê°€ì§€ë¯€ë¡œ, ë¹ ë¥´ê²Œ ìœ ì‚¬ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ìˆì£ .

### ê°œë… 5: ORB-SLAM3 â€” í˜„ì¬ì˜ í‘œì¤€

ORB-SLAM3(2021)ëŠ” ê°€ì¥ ì™„ì„±ë„ ë†’ì€ ì˜¤í”ˆì†ŒìŠ¤ Visual SLAM ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ORB-SLAM ë°œì „ ê³¼ì •:**

| ë²„ì „ | ì—°ë„ | íŠ¹ì§• |
|------|------|------|
| **ORB-SLAM** | 2015 | ë‹¨ì•ˆ Visual SLAM |
| **ORB-SLAM2** | 2017 | ìŠ¤í…Œë ˆì˜¤, RGB-D ì§€ì› |
| **ORB-SLAM3** | 2021 | Visual-Inertial, Multi-map |

**ORB-SLAM3 ì•„í‚¤í…ì²˜:**

> **3ê°œì˜ ë³‘ë ¬ ìŠ¤ë ˆë“œ:**
>
> 1. **Tracking**: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í¬ì¦ˆ ì¶”ì •
> 2. **Local Mapping**: ì§€ì—­ ë§µ ìµœì í™”, í‚¤í”„ë ˆì„ ê´€ë¦¬
> 3. **Loop Closing**: ë£¨í”„ íƒì§€ ë° ì „ì—­ ìµœì í™”

**í•µì‹¬ ëª¨ë“ˆ:**

| ëª¨ë“ˆ | ì—­í•  |
|------|------|
| **ORB ì¶”ì¶œ** | ë¹ ë¥´ê³  ê°•ê±´í•œ íŠ¹ì§•ì  |
| **Covisibility Graph** | ê³µí†µ ë§µí¬ì¸íŠ¸ë¥¼ ê³µìœ í•˜ëŠ” í‚¤í”„ë ˆì„ ì—°ê²° |
| **Essential Graph** | í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”ìš© ìŠ¤íŒ¨ë‹ íŠ¸ë¦¬ |
| **Atlas** | ë‹¤ì¤‘ ë§µ ê´€ë¦¬ (ì—°ê²°ë˜ì§€ ì•Šì€ ì˜ì—­ ì²˜ë¦¬) |
| **IMU í†µí•©** | ë¹ ë¥¸ ì›€ì§ì„ì—ì„œë„ ì•ˆì •ì  ì¶”ì  |

**ORB-SLAM3ê°€ ê°•ë ¥í•œ ì´ìœ :**

1. **ORB íŠ¹ì§•ì **: ë¹ ë¥´ê³ , íšŒì „/ìŠ¤ì¼€ì¼ ë¶ˆë³€
2. **Covisibility ê¸°ë°˜ ìµœì í™”**: íš¨ìœ¨ì ì¸ ë²ˆë“¤ ì¡°ì •
3. **3ê°€ì§€ ì„¼ì„œ ì§€ì›**: ë‹¨ì•ˆ, ìŠ¤í…Œë ˆì˜¤, RGB-D
4. **IMU ìœµí•©**: Visual-Inertial Odometry
5. **Multi-Map**: ì¶”ì  ì‹¤íŒ¨ í›„ ë³µêµ¬ ê°€ëŠ¥

### ê°œë… 6: ë”¥ëŸ¬ë‹ê³¼ SLAM

**ê¸°ì¡´ SLAMì˜ í•œê³„:**

- íŠ¹ì§• ì¶”ì¶œ/ë§¤ì¹­ì´ ì¡°ëª…, í…ìŠ¤ì²˜ì— ë¯¼ê°
- ë™ì  ê°ì²´(ì›€ì§ì´ëŠ” ì‚¬ëŒ, ì°¨) ì²˜ë¦¬ ì–´ë ¤ì›€
- ì‚¬ì „ ì§€ì‹ í™œìš© ë¶€ì¡±

**ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°œì„ :**

| êµ¬ì„± ìš”ì†Œ | ë”¥ëŸ¬ë‹ ì ìš© |
|-----------|-------------|
| **íŠ¹ì§• ì¶”ì¶œ** | SuperPoint, D2-Net |
| **íŠ¹ì§• ë§¤ì¹­** | SuperGlue, LoFTR |
| **ê¹Šì´ ì¶”ì •** | Depth Anything â†’ Dense ë§µ ìƒì„± |
| **ì˜¤ë„ë©”íŠ¸ë¦¬** | DROID-SLAM (end-to-end) |
| **ë™ì  ê°ì²´** | ì„¸ê·¸ë©˜í…Œì´ì…˜ìœ¼ë¡œ ì œì™¸ |

**DROID-SLAM (2021):**

End-to-end ë¯¸ë¶„ ê°€ëŠ¥ SLAM. ë°˜ë³µì ìœ¼ë¡œ ê¹Šì´ì™€ í¬ì¦ˆë¥¼ ì—…ë°ì´íŠ¸í•˜ë©°, ë²ˆë“¤ ì¡°ì •ê¹Œì§€ ë¯¸ë¶„ ê°€ëŠ¥í•˜ê²Œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

**NeRF-SLAM (2023~):**

[NeRF](../17-neural-rendering/01-nerf-basics.md)ë¥¼ SLAMì— í†µí•©í•´ì„œ **í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹± 3D ë§µ**ì„ ìƒì„±í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë§µ ëŒ€ì‹  ë Œë”ë§ ê°€ëŠ¥í•œ ì‹ ê²½ë§ í‘œí˜„ì„ ë§Œë“œëŠ” ê±°ì£ .

## ì‹¤ìŠµ: ê°„ë‹¨í•œ Visual Odometry êµ¬í˜„

### ë‹¨ì•ˆ Visual Odometry

```python
import cv2
import numpy as np

class SimpleVisualOdometry:
    """ê°„ë‹¨í•œ ë‹¨ì•ˆ Visual Odometry"""

    def __init__(self, K, feature_detector='orb'):
        """
        Args:
            K: ì¹´ë©”ë¼ ë‚´ë¶€ í–‰ë ¬ (3x3)
            feature_detector: 'orb' ë˜ëŠ” 'sift'
        """
        self.K = K
        self.focal = K[0, 0]
        self.pp = (K[0, 2], K[1, 2])

        # íŠ¹ì§• ê²€ì¶œê¸°
        if feature_detector == 'orb':
            self.detector = cv2.ORB_create(nfeatures=2000)
        else:
            self.detector = cv2.SIFT_create()

        # BF ë§¤ì²˜
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING if feature_detector == 'orb'
                                 else cv2.NORM_L2, crossCheck=True)

        # ì´ì „ í”„ë ˆì„ ì €ì¥
        self.prev_frame = None
        self.prev_kp = None
        self.prev_desc = None

        # ëˆ„ì  í¬ì¦ˆ
        self.R = np.eye(3)
        self.t = np.zeros((3, 1))

        # ê¶¤ì  ì €ì¥
        self.trajectory = [self.t.copy()]

    def process_frame(self, frame):
        """
        ìƒˆ í”„ë ˆì„ ì²˜ë¦¬, í¬ì¦ˆ ì—…ë°ì´íŠ¸

        Args:
            frame: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€

        Returns:
            R, t: í˜„ì¬ê¹Œì§€ì˜ ëˆ„ì  íšŒì „/ì´ë™
        """
        # íŠ¹ì§• ì¶”ì¶œ
        kp, desc = self.detector.detectAndCompute(frame, None)

        if self.prev_frame is None:
            # ì²« í”„ë ˆì„
            self.prev_frame = frame
            self.prev_kp = kp
            self.prev_desc = desc
            return self.R, self.t

        # íŠ¹ì§• ë§¤ì¹­
        matches = self.bf.match(self.prev_desc, desc)
        matches = sorted(matches, key=lambda x: x.distance)

        # ìƒìœ„ ë§¤ì¹­ ì„ íƒ
        good_matches = matches[:min(100, len(matches))]

        if len(good_matches) < 8:
            print("ë§¤ì¹­ ë¶€ì¡±")
            return self.R, self.t

        # ëŒ€ì‘ì  ì¶”ì¶œ
        pts1 = np.float32([self.prev_kp[m.queryIdx].pt for m in good_matches])
        pts2 = np.float32([kp[m.trainIdx].pt for m in good_matches])

        # ë³¸ì§ˆ í–‰ë ¬ ê³„ì‚°
        E, mask = cv2.findEssentialMat(
            pts2, pts1, self.K,
            method=cv2.RANSAC, prob=0.999, threshold=1.0
        )

        # R, t ë³µì›
        _, R, t, mask = cv2.recoverPose(E, pts2, pts1, self.K)

        # ìŠ¤ì¼€ì¼ (ë‹¨ì•ˆì€ ìŠ¤ì¼€ì¼ì„ ì•Œ ìˆ˜ ì—†ì–´ì„œ 1ë¡œ ê°€ì •)
        scale = 1.0

        # ëˆ„ì  í¬ì¦ˆ ì—…ë°ì´íŠ¸
        self.t = self.t + scale * self.R @ t
        self.R = R @ self.R

        # ê¶¤ì  ì €ì¥
        self.trajectory.append(self.t.copy())

        # ë‹¤ìŒ í”„ë ˆì„ì„ ìœ„í•´ ì €ì¥
        self.prev_frame = frame
        self.prev_kp = kp
        self.prev_desc = desc

        return self.R, self.t

    def get_trajectory(self):
        """ê¶¤ì  ë°˜í™˜ (N, 3)"""
        return np.array([t.flatten() for t in self.trajectory])


def visualize_trajectory(trajectory):
    """2D ê¶¤ì  ì‹œê°í™” (ìœ„ì—ì„œ ë³¸ ì‹œì )"""
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 10))
    plt.plot(trajectory[:, 0], trajectory[:, 2], 'b-', linewidth=1)
    plt.scatter(trajectory[0, 0], trajectory[0, 2], c='g', s=100, label='ì‹œì‘')
    plt.scatter(trajectory[-1, 0], trajectory[-1, 2], c='r', s=100, label='ë')
    plt.xlabel('X (m)')
    plt.ylabel('Z (m)')
    plt.title('ì¹´ë©”ë¼ ê¶¤ì  (Top View)')
    plt.legend()
    plt.axis('equal')
    plt.grid(True)
    plt.savefig('trajectory.png')
    plt.show()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì¹´ë©”ë¼ í–‰ë ¬ (ì˜ˆ: KITTI ë°ì´í„°ì…‹)
    K = np.array([
        [718.856, 0, 607.193],
        [0, 718.856, 185.216],
        [0, 0, 1]
    ])

    vo = SimpleVisualOdometry(K, feature_detector='orb')

    # ë¹„ë””ì˜¤ ë˜ëŠ” ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ë¡œë“œ
    cap = cv2.VideoCapture('driving_video.mp4')

    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        R, t = vo.process_frame(gray)

        # 100í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥
        if frame_count % 100 == 0:
            print(f"Frame {frame_count}: t = {t.flatten()}")

        frame_count += 1

    cap.release()

    # ê¶¤ì  ì‹œê°í™”
    trajectory = vo.get_trajectory()
    visualize_trajectory(trajectory)
    print(f"ì´ {len(trajectory)} í¬ì¦ˆ ì¶”ì • ì™„ë£Œ")
```

### ORB-SLAM3 ì‚¬ìš© ì˜ˆì‹œ

```python
# ORB-SLAM3ëŠ” C++ë¡œ êµ¬í˜„ë˜ì–´ ìˆì–´ Python ë˜í¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.
# ì—¬ê¸°ì„œëŠ” ê°œë…ì ì¸ ì‚¬ìš©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

"""
ORB-SLAM3 ì„¤ì¹˜ ë° ì‹¤í–‰ (Linux):

1. ì˜ì¡´ì„± ì„¤ì¹˜:
   sudo apt install cmake libopencv-dev libeigen3-dev \
                    libpangolin-dev libboost-all-dev

2. ORB-SLAM3 ë¹Œë“œ:
   git clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git
   cd ORB_SLAM3
   chmod +x build.sh
   ./build.sh

3. ì‹¤í–‰ ì˜ˆì‹œ (EuRoC ë°ì´í„°ì…‹, ë‹¨ì•ˆ):
   ./Examples/Monocular/mono_euroc \
       Vocabulary/ORBvoc.txt \
       Examples/Monocular/EuRoC.yaml \
       /path/to/MH_01_easy \
       Examples/Monocular/EuRoC_TimeStamps/MH01.txt
"""

# Pythonì—ì„œ ê¶¤ì  ê²°ê³¼ ë¡œë“œ ë° ë¶„ì„
import numpy as np
import matplotlib.pyplot as plt

def load_orbslam_trajectory(file_path):
    """
    ORB-SLAM3 ê¶¤ì  íŒŒì¼ ë¡œë“œ

    í¬ë§·: timestamp tx ty tz qx qy qz qw
    """
    data = np.loadtxt(file_path)

    timestamps = data[:, 0]
    positions = data[:, 1:4]   # tx, ty, tz
    quaternions = data[:, 4:]  # qx, qy, qz, qw

    return timestamps, positions, quaternions


def plot_trajectory_comparison(gt_path, est_path):
    """Ground Truthì™€ ì¶”ì • ê¶¤ì  ë¹„êµ"""

    ts_gt, pos_gt, _ = load_orbslam_trajectory(gt_path)
    ts_est, pos_est, _ = load_orbslam_trajectory(est_path)

    fig = plt.figure(figsize=(12, 5))

    # 3D ê¶¤ì 
    ax1 = fig.add_subplot(121, projection='3d')
    ax1.plot(pos_gt[:, 0], pos_gt[:, 1], pos_gt[:, 2], 'g-', label='GT')
    ax1.plot(pos_est[:, 0], pos_est[:, 1], pos_est[:, 2], 'r-', label='Estimated')
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z')
    ax1.legend()
    ax1.set_title('3D ê¶¤ì ')

    # Top view
    ax2 = fig.add_subplot(122)
    ax2.plot(pos_gt[:, 0], pos_gt[:, 2], 'g-', label='GT')
    ax2.plot(pos_est[:, 0], pos_est[:, 2], 'r-', label='Estimated')
    ax2.set_xlabel('X')
    ax2.set_ylabel('Z')
    ax2.legend()
    ax2.set_title('Top View')
    ax2.axis('equal')

    plt.tight_layout()
    plt.savefig('trajectory_comparison.png')
    plt.show()


# ì‚¬ìš© ì˜ˆì‹œ
# plot_trajectory_comparison('gt_trajectory.txt', 'estimated_trajectory.txt')
```

### ê°„ë‹¨í•œ ë£¨í”„ í´ë¡œì§• ê°œë…

```python
import cv2
import numpy as np
from collections import defaultdict

class SimpleBagOfWords:
    """ê°„ë‹¨í•œ Bag of Words êµ¬í˜„"""

    def __init__(self, vocab_size=100):
        self.vocab_size = vocab_size
        self.vocabulary = None
        self.orb = cv2.ORB_create(nfeatures=500)

    def build_vocabulary(self, images):
        """ì´ë¯¸ì§€ë“¤ì—ì„œ ì‹œê° ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•"""
        all_descriptors = []

        for img in images:
            kp, desc = self.orb.detectAndCompute(img, None)
            if desc is not None:
                all_descriptors.append(desc)

        all_descriptors = np.vstack(all_descriptors).astype(np.float32)

        # K-Means í´ëŸ¬ìŠ¤í„°ë§
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.1)
        _, labels, centers = cv2.kmeans(
            all_descriptors, self.vocab_size, None, criteria, 10,
            cv2.KMEANS_PP_CENTERS
        )

        self.vocabulary = centers
        print(f"Vocabulary êµ¬ì¶• ì™„ë£Œ: {self.vocab_size} words")

    def image_to_bow(self, img):
        """ì´ë¯¸ì§€ë¥¼ BoW íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ë³€í™˜"""
        kp, desc = self.orb.detectAndCompute(img, None)

        if desc is None or self.vocabulary is None:
            return np.zeros(self.vocab_size)

        # ê° ë””ìŠ¤í¬ë¦½í„°ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì‹œê° ë‹¨ì–´ì— í• ë‹¹
        bf = cv2.BFMatcher(cv2.NORM_HAMMING)
        matches = bf.match(desc, self.vocabulary.astype(np.uint8))

        # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
        bow = np.zeros(self.vocab_size)
        for m in matches:
            bow[m.trainIdx] += 1

        # ì •ê·œí™”
        if bow.sum() > 0:
            bow = bow / bow.sum()

        return bow

    def similarity(self, bow1, bow2):
        """ë‘ BoW íˆìŠ¤í† ê·¸ë¨ì˜ ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
        dot = np.dot(bow1, bow2)
        norm1 = np.linalg.norm(bow1)
        norm2 = np.linalg.norm(bow2)

        if norm1 == 0 or norm2 == 0:
            return 0

        return dot / (norm1 * norm2)


class SimpleLoopDetector:
    """ê°„ë‹¨í•œ ë£¨í”„ íƒì§€ê¸°"""

    def __init__(self, similarity_threshold=0.8, min_interval=50):
        self.bow = SimpleBagOfWords(vocab_size=100)
        self.keyframe_bows = []  # í‚¤í”„ë ˆì„ BoW ì €ì¥
        self.similarity_threshold = similarity_threshold
        self.min_interval = min_interval  # ìµœì†Œ í”„ë ˆì„ ê°„ê²©

    def add_keyframe(self, img):
        """í‚¤í”„ë ˆì„ ì¶”ê°€, ë£¨í”„ íƒì§€"""
        bow = self.bow.image_to_bow(img)
        current_idx = len(self.keyframe_bows)

        loop_candidate = None
        best_similarity = 0

        # ì´ì „ í‚¤í”„ë ˆì„ë“¤ê³¼ ë¹„êµ (ìµœê·¼ ê²ƒì€ ì œì™¸)
        for i, prev_bow in enumerate(self.keyframe_bows):
            if current_idx - i < self.min_interval:
                continue  # ë„ˆë¬´ ê°€ê¹Œìš´ í”„ë ˆì„ì€ ë¬´ì‹œ

            sim = self.bow.similarity(bow, prev_bow)

            if sim > best_similarity and sim > self.similarity_threshold:
                best_similarity = sim
                loop_candidate = i

        self.keyframe_bows.append(bow)

        if loop_candidate is not None:
            print(f"ğŸ”„ ë£¨í”„ íƒì§€! Frame {current_idx} â†” Frame {loop_candidate} "
                  f"(similarity: {best_similarity:.3f})")

        return loop_candidate


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
    cap = cv2.VideoCapture('indoor_walk.mp4')

    # ë¨¼ì € ì¼ë¶€ í”„ë ˆì„ìœ¼ë¡œ vocabulary êµ¬ì¶•
    sample_frames = []
    for i in range(100):
        ret, frame = cap.read()
        if ret and i % 10 == 0:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            sample_frames.append(gray)

    loop_detector = SimpleLoopDetector()
    loop_detector.bow.build_vocabulary(sample_frames)

    # ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 10í”„ë ˆì„ë§ˆë‹¤ í‚¤í”„ë ˆì„ìœ¼ë¡œ ì¶”ê°€
        if frame_idx % 10 == 0:
            loop_candidate = loop_detector.add_keyframe(gray)

        frame_idx += 1

    cap.release()
    print(f"ì´ {len(loop_detector.keyframe_bows)} í‚¤í”„ë ˆì„ ì²˜ë¦¬")
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°: SLAMì˜ ì—­ì‚¬

**1986ë…„ â€” SLAM ìš©ì–´ì˜ íƒ„ìƒ**

"SLAM"ì´ë¼ëŠ” ìš©ì–´ëŠ” 1986ë…„ IEEE ë¡œë³´í‹±ìŠ¤ ë° ìë™í™” í•™íšŒì—ì„œ ì²˜ìŒ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ë‹¹ì‹œì—ëŠ” ë¡œë´‡ì— ë‹¬ë¦° ì†Œë‚˜ë‚˜ ë ˆì´ì € ì„¼ì„œë¥¼ ì‚¬ìš©í–ˆì£ . í™•ë¥ ì  ì ‘ê·¼ë²•(ì¹¼ë§Œ í•„í„°, íŒŒí‹°í´ í•„í„°)ì´ ì£¼ë¥¼ ì´ë¤˜ìŠµë‹ˆë‹¤.

**2007ë…„ â€” MonoSLAM**

ìµœì´ˆì˜ ì‹¤ì‹œê°„ ë‹¨ì•ˆ Visual SLAM. ì¹´ë©”ë¼ í•œ ëŒ€ë¡œ SLAMì´ ê°€ëŠ¥í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ˆê¸°í™”ê°€ ì–´ë µê³ , ë“œë¦¬í”„íŠ¸ê°€ ì‹¬í–ˆì£ .

**2015ë…„ â€” ORB-SLAM**

ìŠ¤í˜ì¸ ì‚¬ë¼ê³ ì‚¬ ëŒ€í•™ì˜ RaÃºl Mur-Artalì´ ë°œí‘œí•œ ORB-SLAMì€ **ê²Œì„ ì²´ì¸ì €**ì˜€ìŠµë‹ˆë‹¤. ORB íŠ¹ì§•ì ì˜ ë¹ ë¥¸ ì†ë„, Covisibility Graphì˜ íš¨ìœ¨ì ì¸ ìµœì í™”, ê°•ë ¥í•œ ë£¨í”„ í´ë¡œì§•ì´ ê²°í•©ë˜ì–´, ì²˜ìŒìœ¼ë¡œ **ì‹¤ìš©ì ì¸** Visual SLAMì´ ë˜ì—ˆìŠµë‹ˆë‹¤.

**2021ë…„ â€” ORB-SLAM3ì™€ DROID-SLAM**

ORB-SLAM3ëŠ” Visual-Inertial ìœµí•©ê³¼ ë‹¤ì¤‘ ë§µ ê´€ë¦¬ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ê°™ì€ í•´ DROID-SLAMì´ end-to-end ë”¥ëŸ¬ë‹ SLAMì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤¬ì£ .

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "SLAMì€ GPSë¥¼ ëŒ€ì²´í•œë‹¤"
>
> SLAMì€ **ìƒëŒ€ì  ìœ„ì¹˜**ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. ì ˆëŒ€ ìœ„ì¹˜(ìœ„ë„, ê²½ë„)ë¥¼ ì•Œë ¤ë©´ ì™¸ë¶€ ì°¸ì¡°(GPS, ê¸°ì§€êµ­ ë“±)ê°€ í•„ìš”í•©ë‹ˆë‹¤. SLAMì€ GPSê°€ ì•ˆ ë˜ëŠ” í™˜ê²½ì—ì„œ **ë¡œì»¬ ìœ„ì¹˜**ë¥¼ ì¶”ì •í•˜ê±°ë‚˜, GPSì™€ **ë³´ì™„ì ìœ¼ë¡œ** ì‚¬ìš©ë©ë‹ˆë‹¤.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?**: ë‹¨ì•ˆ SLAMì˜ ê°€ì¥ í° ë¬¸ì œëŠ” **ìŠ¤ì¼€ì¼ ëª¨í˜¸ì„±**ì…ë‹ˆë‹¤. ì¹´ë©”ë¼ í•œ ëŒ€ë¡œëŠ” ë¬¼ì²´ê°€ ì‘ê³  ê°€ê¹Œìš´ì§€, í¬ê³  ë¨¼ì§€ êµ¬ë¶„í•  ìˆ˜ ì—†ì£ . IMUë¥¼ ì¶”ê°€í•˜ë©´ ê°€ì†ë„ë¡œ ìŠ¤ì¼€ì¼ì„ ì¶”ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: Visual SLAMì€ **í…ìŠ¤ì²˜ê°€ ì—†ëŠ” í™˜ê²½**(í° ë²½, ë¹ˆ ë³µë„)ì—ì„œ ì‹¤íŒ¨í•©ë‹ˆë‹¤. ì´ëŸ° í™˜ê²½ì—ì„œëŠ” IMU ìœµí•©ì´ë‚˜ LiDAR ë³´ì¡°ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: ë£¨í”„ í´ë¡œì§•ì€ **ê¸´ ê²½ë¡œì—ì„œ í•„ìˆ˜**ì…ë‹ˆë‹¤. 100më§Œ ì´ë™í•´ë„ ë“œë¦¬í”„íŠ¸ê°€ ë¯¸í„° ë‹¨ìœ„ë¡œ ìŒ“ì…ë‹ˆë‹¤. ì¶œë°œì ìœ¼ë¡œ ëŒì•„ì˜¤ëŠ” ê²½ë¡œë¥¼ ê³„íší•˜ë©´ ìë™ìœ¼ë¡œ ì˜¤ì°¨ê°€ ìˆ˜ì •ë©ë‹ˆë‹¤.

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **SLAM** | ìœ„ì¹˜ ì¶”ì •ê³¼ ì§€ë„ ìƒì„±ì„ ë™ì‹œì— ìˆ˜í–‰ |
| **Visual Odometry** | ì—°ì† í”„ë ˆì„ ê°„ ìƒëŒ€ì  ì›€ì§ì„ ì¶”ì • |
| **í‚¤í”„ë ˆì„** | ì¤‘ìš” í”„ë ˆì„ë§Œ ì„ íƒí•´ì„œ íš¨ìœ¨ì  ê´€ë¦¬ |
| **ë£¨í”„ í´ë¡œì§•** | ì¬ë°©ë¬¸ ì¸ì‹ìœ¼ë¡œ ëˆ„ì  ì˜¤ì°¨ ìˆ˜ì • |
| **ë²ˆë“¤ ì¡°ì •** | í¬ì¦ˆì™€ ë§µí¬ì¸íŠ¸ ë™ì‹œ ìµœì í™” |
| **ORB-SLAM3** | í˜„ì¬ ê°€ì¥ ì™„ì„±ë„ ë†’ì€ ì˜¤í”ˆì†ŒìŠ¤ SLAM |

## ë‹¤ìŒ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°

SLAMìœ¼ë¡œ ì¹´ë©”ë¼ì˜ ê¶¤ì ê³¼ í¬ì†Œí•œ 3D ë§µì„ ì–»ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ [3D ë³µì›](./05-3d-reconstruction.md)ì—ì„œëŠ” ì—¬ëŸ¬ ì´ë¯¸ì§€ë¡œë¶€í„° **ë°€ì§‘í•œ(Dense) 3D ëª¨ë¸**ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. Structure from Motion(SfM)ê³¼ Multi-View Stereo(MVS)ë¡œ ì‚¬ì§„ì—ì„œ ì™„ì „í•œ 3D ë©”ì‹œë¥¼ ë§Œë“œëŠ” ê³¼ì •ì„ ì‚´í´ë´…ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [ORB-SLAM3 GitHub](https://github.com/UZ-SLAMLab/ORB_SLAM3) - ê³µì‹ êµ¬í˜„ì²´
- [A Review of Visual SLAM (2024)](https://www.frontiersin.org/articles/10.3389/frobt.2024.1347985/full) - ìµœì‹  ì„œë² ì´
- [SLAM Tutorial (Berkeley)](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf) - ê¸°ì´ˆ íŠœí† ë¦¬ì–¼
- [Visual SLAM: Why Bundle Adjust?](https://arxiv.org/abs/1902.03747) - ë²ˆë“¤ ì¡°ì • í•´ì„¤
- [DROID-SLAM ë…¼ë¬¸](https://arxiv.org/abs/2108.10869) - ë”¥ëŸ¬ë‹ SLAM
